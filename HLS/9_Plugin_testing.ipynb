{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2295e09-ec16-4e2e-a6fa-e70e37f8453b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall ndvi_tools -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4f6711-35a3-413f-af5d-58158b6a58aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ndvi_tools/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55a46c0-cdbf-4b29-a820-795a74f53e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "from odc.stats.tasks import TaskReader\n",
    "from odc.stats.model import OutputProduct\n",
    "\n",
    "import datacube\n",
    "from deafrica_tools.plotting import display_map\n",
    "from deafrica_tools.dask import create_local_dask_cluster\n",
    "\n",
    "from ndvi_tools.ndvi_climatology_plugin import NDVIclimatology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc418d6-d6b7-4f29-b93d-176a8e2cc0fb",
   "metadata": {},
   "source": [
    "## Test functions without odc-stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9205fb-676f-4b1c-aac7-61c9e44309be",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_local_dask_cluster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae62e5e7-3ca5-48e0-b531-a2474d19d163",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = datacube.Datacube(app=\"Vegetation_anomalies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d627297-c6b1-4a4b-bf8a-bd20a333aa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat, lon = 34.5117, -5.9119\n",
    "buffer = 0.05\n",
    "# Set the range of dates for the climatology\n",
    "time_range = ('2014', '2016')\n",
    "resolution = (-60, 60)\n",
    "\n",
    "lat_range = (lat-buffer, lat+buffer)\n",
    "lon_range = (lon-buffer, lon+buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70488c1e-1fff-438e-b72a-31d5c447f39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_map(x=lon_range, y=lat_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e2280a-03cb-4ef9-abd3-4bcf05bbb78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {\n",
    "    'x': lon_range,\n",
    "    'y': lat_range,\n",
    "    'time': time_range,\n",
    "    'resolution': resolution,\n",
    "    'output_crs':'epsg:6933',\n",
    "    'measurements':['red','nir','pixel_quality'],\n",
    "    'group_by':'solar_day'\n",
    "#     'dask_chunks':dask_chunks\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeaba758-9f67-43e5-8c05-4eb20876fd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = dc.load(product='ls8_sr', dask_chunks={}, **query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c2ed95-ba72-4c7a-b0a6-f3b7a00223f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls7_dss = dc.find_datasets(product='ls7_sr', **query)\n",
    "ls8_dss = dc.find_datasets(product='ls8_sr', **query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3d5954-5a80-4fa4-8ca2-d3577803ac3d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from typing import Any, Dict, Iterable, Optional, Sequence, Tuple\n",
    "\n",
    "# import xarray as xr\n",
    "# import numpy as np\n",
    "# from odc.stats.model import Task\n",
    "# from datacube.utils import masking\n",
    "# from odc.algo import keep_good_only, erase_bad\n",
    "# from odc.algo._masking import mask_cleanup\n",
    "# from odc.stats.model import StatsPluginInterface\n",
    "# from odc.stats import _plugins\n",
    "# from odc.algo.io import load_with_native_transform\n",
    "\n",
    "\n",
    "# class NDVIClimatology(StatsPluginInterface):\n",
    "#     NAME = \"ndvi_climatology\"\n",
    "#     SHORT_NAME = NAME\n",
    "#     VERSION = \"0.0.1\"\n",
    "\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         resampling: str = \"bilinear\",\n",
    "#         bands: Optional[Sequence[str]] = [\"red\", \"nir\"],\n",
    "#         databases: Dict[str, Optional[Any]] = None,\n",
    "#         mask_band: str = \"QA_PIXEL\",\n",
    "#         flags_ls57: Dict[str, Optional[Any]] = dict(\n",
    "#             cloud=\"high_confidence\", cloud_shadow=\"high_confidence\"\n",
    "#         ),\n",
    "#         flags_ls8: Dict[str, Optional[Any]] = dict(\n",
    "#             cloud=\"high_confidence\",\n",
    "#             cloud_shadow=\"high_confidence\",\n",
    "#             cirrus=\"high_confidence\"\n",
    "#         ),\n",
    "#         nodata_flags: Dict[str, Optional[Any]] = dict(nodata=False),\n",
    "#         filters: Optional[Iterable[Tuple[str, int]]] = None,\n",
    "#         work_chunks: Dict[str, Optional[Any]] = dict(x=400, y=400),\n",
    "#         scale: float = 0.0000275,\n",
    "#         offset: float = -0.2,\n",
    "#         output_dtype: str = \"float32\",\n",
    "#         **kwargs,\n",
    "#     ):\n",
    "\n",
    "#         self.bands = bands\n",
    "#         self.mask_band = mask_band\n",
    "#         self.databases = databases\n",
    "#         self.input_bands = self.bands.append(mask_band)\n",
    "#         self.flags_ls57 = flags_ls57\n",
    "#         self.flags_ls8 = flags_ls8\n",
    "#         self.resampling = resampling\n",
    "#         self.nodata_flags = nodata_flags\n",
    "#         self.filters = filters\n",
    "#         self.work_chunks = work_chunks\n",
    "#         self.scale = scale\n",
    "#         self.offset = offset\n",
    "#         self.output_dtype = np.dtype(output_dtype)\n",
    "#         self.output_nodata = np.nan\n",
    "\n",
    "#     @property\n",
    "#     def measurements(self) -> Tuple[str, ...]:\n",
    "#         return self.bands\n",
    "\n",
    "#     def input_data(self, task: Task) -> xr.Dataset:\n",
    "#         \"\"\"\n",
    "#         Load each of the sensors, remove cloud and poor data,\n",
    "#         apply scaling coefficients to LS5 & 7 NDVI to mimic\n",
    "#         NDVI of Landsat 8. Return the harmonized NDVI time series\n",
    "#         \"\"\"\n",
    "\n",
    "#         def masking_data(xx, flags):\n",
    "#             \"\"\"\n",
    "#             Loads in the data in the native projection. It performs the following:\n",
    "\n",
    "#             1. Loads pq bands\n",
    "#             2. Extract valid - by removing negative pixel using masking_scale from input bands\n",
    "#             3. Extract cloud_mask flags from bands\n",
    "#             4. Drop nodata and negative pixels\n",
    "#             5. Add cloud_mask band to xx for fuser and reduce\n",
    "#             \"\"\"\n",
    "\n",
    "#             # remove negative pixels - a pixel is invalid if any of the band is smaller than masking_scale\n",
    "#             valid = (\n",
    "#                 (xx[self.bands] > (-1.0 * self.offset / self.scale))\n",
    "#                 .to_array(dim=\"band\")\n",
    "#                 .all(dim=\"band\")\n",
    "#             )\n",
    "\n",
    "#             mask_band = xx[self.mask_band]\n",
    "#             xx = xx.drop_vars([self.mask_band])\n",
    "\n",
    "#             flags_def = masking.get_flags_def(mask_band)\n",
    "\n",
    "#             # set cloud_mask - True=cloud, False=non-cloud\n",
    "#             mask, _ = masking.create_mask_value(flags_def, **flags)\n",
    "#             cloud_mask = (mask_band & mask) != 0\n",
    "\n",
    "#             # set no_data bitmask - True=data, False=no-data\n",
    "#             nodata_mask, _ = masking.create_mask_value(flags_def, **self.nodata_flags)\n",
    "#             keeps = (mask_band & nodata_mask) == 0\n",
    "\n",
    "#             xx = keep_good_only(xx, valid)  # remove negative pixels\n",
    "#             xx = keep_good_only(xx, keeps)  # remove nodata pixels\n",
    "#             xx[\"cloud_mask\"] = cloud_mask\n",
    "\n",
    "#             return xx\n",
    "\n",
    "#         # load landsat 5 & 7\n",
    "#         ls57 = load_with_native_transform(\n",
    "#             dss=self.databases[\"ls57\"],\n",
    "#             geobox=task.geobox,\n",
    "#             native_transform=lambda x: masking_data(x, self.flags_ls57),\n",
    "#             bands=self.bands,\n",
    "#             chunks=self.work_chunks,\n",
    "#             resampling=self.resampling,\n",
    "#         )\n",
    "\n",
    "#         # load Landsat 8\n",
    "#         ls8 = load_with_native_transform(\n",
    "#             dss=self.databases[\"ls8\"],\n",
    "#             geobox=task.geobox,\n",
    "#             native_transform=lambda x: masking_data(x, self.flags_ls8),\n",
    "#             bands=self.bands,\n",
    "#             chunks=self.work_chunks,\n",
    "#             resampling=self.resampling,\n",
    "#         )\n",
    "\n",
    "#         # add datasets to dict\n",
    "#         ds = dict(ls57=ls57, ls8=ls8)\n",
    "\n",
    "#         # Loop through datasets, rescale to SR, calculate NDVI\n",
    "#         for k in ds:\n",
    "\n",
    "#             cloud_mask = ds[k][\"cloud_mask\"]\n",
    "\n",
    "#             if self.filters is not None:\n",
    "#                 cloud_mask = mask_cleanup(\n",
    "#                     ds[k][\"cloud_mask\"], mask_filters=self.filters\n",
    "#                 )\n",
    "\n",
    "#             # erase pixels with cloud\n",
    "#             ds[k] = ds[k].drop_vars([\"cloud_mask\"])\n",
    "#             ds[k] = erase_bad(ds[k], cloud_mask)\n",
    "\n",
    "#             # rescale bands into surface reflectance scale\n",
    "#             for band in ds[k].data_vars.keys():\n",
    "#                 # set nodata_mask - use for resetting nodata pixel after rescale\n",
    "#                 nodata_mask = ds[k][band] == ds[k][band].attrs.get(\"nodata\")\n",
    "#                 # rescale\n",
    "#                 ds[k][band] = self.scale * ds[k][band] + self.offset\n",
    "#                 #  apply nodata_mask - reset nodata pixels to output-nodata\n",
    "#                 ds[k][band] = ds[k][band].where(~nodata_mask, self.output_nodata)\n",
    "#                 # set data-type and nodata attrs\n",
    "#                 ds[k][band] = ds[k][band].astype(self.output_dtype)\n",
    "#                 ds[k][band].attrs[\"nodata\"] = self.output_nodata\n",
    "\n",
    "#             # calculate ndvi\n",
    "#             ds[k][\"ndvi\"] = (ds[k].nir - ds[k].red) / (ds[k].nir + ds[k].red)\n",
    "\n",
    "#         # scaling of 5-7 NDVI to match NDVI 8\n",
    "#         slope = 0.988\n",
    "#         intercept = -0.015\n",
    "#         ds[\"ls57\"][\"ndvi\"] = (ds[\"ls57\"][\"ndvi\"] - intercept) / slope\n",
    "\n",
    "#         # combine datarrays and convert back to dataset\n",
    "#         ndvi = ds[\"ls57\"].ndvi.combine_first(ds[\"ls8\"].ndvi)\n",
    "#         ndvi = ndvi.to_dataset(name=\"ndvi\")\n",
    "\n",
    "#         return ndvi\n",
    "\n",
    "#     def reduce(self, xx: xr.Dataset) -> xr.Dataset:\n",
    "#         \"\"\"\n",
    "#         Collapse the NDVI time series using mean\n",
    "#         and std. dev.\n",
    "#         \"\"\"\n",
    "#         ## climatology calulations\n",
    "#         months = {\n",
    "#             \"jan\": [1],\n",
    "#             \"feb\": [2],\n",
    "#             \"mar\": [3],\n",
    "#             \"apr\": [4],\n",
    "#             \"may\": [5],\n",
    "#             \"jun\": [6],\n",
    "#             \"jul\": [7],\n",
    "#             \"aug\": [8],\n",
    "#             \"sep\": [9],\n",
    "#             \"oct\": [10],\n",
    "#             \"nov\": [11],\n",
    "#             \"dec\": [12],\n",
    "#         }\n",
    "\n",
    "#         xx_mean = ndvi.groupby(ndvi.spec[\"time.month\"]).mean()\n",
    "#         xx_std = ndvi.groupby(ndvi.spec[\"time.month\"]).std()\n",
    "#         ndvi_var_mean = []\n",
    "#         ndvi_var_std = []\n",
    "#         for m in months:\n",
    "#             ix_mean = xx_mean.sel(month=months[m])\n",
    "#             ix_mean = (\n",
    "#                 ix_mean.to_array(name=\"ndvi_clim_mean_\" + m).drop(\"variable\").squeeze()\n",
    "#             )\n",
    "#             ix_std = xx_std.sel(month=months[m])\n",
    "#             ix_std = (\n",
    "#                 ix_std.to_array(name=\"ndvi_clim_std_\" + m).drop(\"variable\").squeeze()\n",
    "#             )\n",
    "#             ndvi_var_mean.append(ix_mean)\n",
    "#             ndvi_var_std.append(ix_std)\n",
    "\n",
    "#         clim = xr.merge(ndvi_var_mean + ndvi_var_std, compat=\"override\").drop(\"month\")\n",
    "\n",
    "#         return clim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e404dc-3349-4cc1-a58e-f6bd55d85423",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    resampling=\"bilinear\",\n",
    "    databases=dict(ls57=ls7_dss, ls8=ls8_dss),\n",
    "    bands=[\"red\", \"nir\"],\n",
    "    mask_band=\"QA_PIXEL\",\n",
    "    mask_filters=[[\"opening\", 5], [\"dilation\", 5]],\n",
    "    flags_ls57=dict(cloud=\"high_confidence\", cloud_shadow=\"high_confidence\"),\n",
    "    flags_ls8=dict(\n",
    "        cloud=\"high_confidence\",\n",
    "        cloud_shadow=\"high_confidence\",\n",
    "        cirrus=\"high_confidence\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789a8629-533d-4ea6-aa00-0915708171da",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=ndvi_climatology(**config)\n",
    "ndvi = x.input_data(task)\n",
    "result = x.reduce(ndvi).compute()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7808d0-ae09-4c6f-bfaf-367bc13706ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig,ax=plt.subplots(1,12, sharex=True, sharey=True, figsize=(30,4))\n",
    "for i,j in zip(range(0,12), [\"jan\",\"feb\",\"mar\", \"apr\", \"may\", \"jun\", \"jul\", \"aug\", \"sep\", \"oct\", \"nov\", \"dec\"]):\n",
    "    result['ndvi_clim_mean_'+j].plot.imshow(ax=ax[i], add_colorbar=False, vmin=0)\n",
    "    ax[i].set_title(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b69c141-15a6-4a30-a8a0-8ccf0f394b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig,ax=plt.subplots(1,12, sharex=True, sharey=True, figsize=(30,4))\n",
    "for i,j in zip(range(0,12), [\"jan\",\"feb\",\"mar\", \"apr\", \"may\", \"jun\", \"jul\", \"aug\", \"sep\", \"oct\", \"nov\", \"dec\"]):\n",
    "    result['ndvi_clim_std_'+j].plot.imshow(ax=ax[i], add_colorbar=False)\n",
    "    ax[i].set_title(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f114407c-6bb2-408a-8e16-461402c30b43",
   "metadata": {},
   "source": [
    "## Test functions with odc-stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a222f75-2cde-4b93-9eaa-1af52f4c36bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73d77b1-d525-4aae-b88a-34b40d484741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !odc-stats save-tasks --frequency annual --grid africa-30 --temporal-range 2014--P2Y ls7_sr --frequency all --dataset-filter '{\"collection_category\": \"T1\"}'\n",
    "# !odc-stats save-tasks --frequency annual --grid africa-30 --temporal-range 2014--P2Y ls8_sr --frequency all --dataset-filter '{\"collection_category\": \"T1\"}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709b9d38-3dac-49ad-a965-9f9afdd038ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "os.system(\"odc-stats run \"\\\n",
    "          \"ls8_sr_2014--P2Y.db \"\\\n",
    "          \"--config=ndvi_climatology.yaml \"\\\n",
    "          \"--resolution=60 \"\\\n",
    "          \"--threads=4 \"\\\n",
    "          \"--memory-limit=29Gi \"\\\n",
    "          \"--location=file:///home/jovyan/git/deafrica-sandbox-notebooks/frica-sandbox-notebooks/HLS/{product}/{version} \"+str(1200)\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12b8c5d-3c98-482a-a54c-c278678d1164",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r -f ndvi_tools/ndvi_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75517bf6-850f-41c2-bcc2-5b870c6ce558",
   "metadata": {},
   "outputs": [],
   "source": [
    "!odc-stats run ls7_sr_2014--P2Y.db --config=ndvi_climatology.yaml --resolution=60 --threads=4 --memory-limit=29Gi --location=file:///home/jovyan/git/deafrica-sandbox-notebooks/frica-sandbox-notebooks/HLS/{product}/{version}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80534f0c-89c1-4c6e-bca2-401c48735f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "taskdb = TaskReader('s3://deafrica-services/crop_mask_eastern/1-0-0/gm_s2_semiannual_all.db', product=op)\n",
    "task = taskdb.load_task(('2019--P1Y', t[0], t[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
