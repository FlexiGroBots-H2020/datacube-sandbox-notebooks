{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "866bdc15-6084-42df-a64a-52a9b6337e44",
   "metadata": {},
   "source": [
    "# Testing performance of sklearn_flatten and sklearn_unflatten vs raster_stack and raster_unstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d84b8d74-a3c8-400f-8898-a6a4ae411900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the necessary Python packages.\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "import datacube\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolours\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score\n",
    ")\n",
    "\n",
    "from deafrica_tools.datahandling import load_ard\n",
    "from deafrica_tools.plotting import display_map, plot_lulc\n",
    "from deafrica_tools.classification import sklearn_flatten, sklearn_unflatten\n",
    "from deafrica_tools.dask import create_local_dask_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41ace9bf-00c9-4e14-b569-59729ad1f8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = datacube.Datacube(app=\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af595cd7-fee8-4f3f-b2e1-7abdac8a88c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><span style=\"color:#565656\">Make this Notebook Trusted to load map: File -> Trust Notebook</span><iframe src=\"about:blank\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" data-html=%3C%21DOCTYPE%20html%3E%0A%3Chead%3E%20%20%20%20%0A%20%20%20%20%3Cmeta%20http-equiv%3D%22content-type%22%20content%3D%22text/html%3B%20charset%3DUTF-8%22%20/%3E%0A%20%20%20%20%0A%20%20%20%20%20%20%20%20%3Cscript%3E%0A%20%20%20%20%20%20%20%20%20%20%20%20L_NO_TOUCH%20%3D%20false%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20L_DISABLE_3D%20%3D%20false%3B%0A%20%20%20%20%20%20%20%20%3C/script%3E%0A%20%20%20%20%0A%20%20%20%20%3Cstyle%3Ehtml%2C%20body%20%7Bwidth%3A%20100%25%3Bheight%3A%20100%25%3Bmargin%3A%200%3Bpadding%3A%200%3B%7D%3C/style%3E%0A%20%20%20%20%3Cstyle%3E%23map%20%7Bposition%3Aabsolute%3Btop%3A0%3Bbottom%3A0%3Bright%3A0%3Bleft%3A0%3B%7D%3C/style%3E%0A%20%20%20%20%3Cscript%20src%3D%22https%3A//cdn.jsdelivr.net/npm/leaflet%401.6.0/dist/leaflet.js%22%3E%3C/script%3E%0A%20%20%20%20%3Cscript%20src%3D%22https%3A//code.jquery.com/jquery-1.12.4.min.js%22%3E%3C/script%3E%0A%20%20%20%20%3Cscript%20src%3D%22https%3A//maxcdn.bootstrapcdn.com/bootstrap/3.2.0/js/bootstrap.min.js%22%3E%3C/script%3E%0A%20%20%20%20%3Cscript%20src%3D%22https%3A//cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js%22%3E%3C/script%3E%0A%20%20%20%20%3Clink%20rel%3D%22stylesheet%22%20href%3D%22https%3A//cdn.jsdelivr.net/npm/leaflet%401.6.0/dist/leaflet.css%22/%3E%0A%20%20%20%20%3Clink%20rel%3D%22stylesheet%22%20href%3D%22https%3A//maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css%22/%3E%0A%20%20%20%20%3Clink%20rel%3D%22stylesheet%22%20href%3D%22https%3A//maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap-theme.min.css%22/%3E%0A%20%20%20%20%3Clink%20rel%3D%22stylesheet%22%20href%3D%22https%3A//maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css%22/%3E%0A%20%20%20%20%3Clink%20rel%3D%22stylesheet%22%20href%3D%22https%3A//cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css%22/%3E%0A%20%20%20%20%3Clink%20rel%3D%22stylesheet%22%20href%3D%22https%3A//cdn.jsdelivr.net/gh/python-visualization/folium/folium/templates/leaflet.awesome.rotate.min.css%22/%3E%0A%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%3Cmeta%20name%3D%22viewport%22%20content%3D%22width%3Ddevice-width%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20initial-scale%3D1.0%2C%20maximum-scale%3D1.0%2C%20user-scalable%3Dno%22%20/%3E%0A%20%20%20%20%20%20%20%20%20%20%20%20%3Cstyle%3E%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23map_570c6dc6564f4a52a28d3e22f33a7c96%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20position%3A%20relative%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20width%3A%20100.0%25%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20height%3A%20100.0%25%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20left%3A%200.0%25%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20top%3A%200.0%25%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20%20%20%20%20%20%20%3C/style%3E%0A%20%20%20%20%20%20%20%20%0A%3C/head%3E%0A%3Cbody%3E%20%20%20%20%0A%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%3Cdiv%20class%3D%22folium-map%22%20id%3D%22map_570c6dc6564f4a52a28d3e22f33a7c96%22%20%3E%3C/div%3E%0A%20%20%20%20%20%20%20%20%0A%3C/body%3E%0A%3Cscript%3E%20%20%20%20%0A%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20var%20map_570c6dc6564f4a52a28d3e22f33a7c96%20%3D%20L.map%28%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22map_570c6dc6564f4a52a28d3e22f33a7c96%22%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20center%3A%20%5B-1.2933%2C%2036.8379%5D%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20crs%3A%20L.CRS.EPSG3857%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20zoom%3A%2011%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20zoomControl%3A%20true%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20preferCanvas%3A%20false%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20%20%20%20%20%20%20%29%3B%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%0A%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20var%20tile_layer_95dae2ef719b4524aebec55484184f7d%20%3D%20L.tileLayer%28%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22http%3A//mt1.google.com/vt/lyrs%3Dy%5Cu0026z%3D%7Bz%7D%5Cu0026x%3D%7Bx%7D%5Cu0026y%3D%7By%7D%22%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7B%22attribution%22%3A%20%22Google%22%2C%20%22detectRetina%22%3A%20false%2C%20%22maxNativeZoom%22%3A%2018%2C%20%22maxZoom%22%3A%2018%2C%20%22minZoom%22%3A%200%2C%20%22noWrap%22%3A%20false%2C%20%22opacity%22%3A%201%2C%20%22subdomains%22%3A%20%22abc%22%2C%20%22tms%22%3A%20false%7D%0A%20%20%20%20%20%20%20%20%20%20%20%20%29.addTo%28map_570c6dc6564f4a52a28d3e22f33a7c96%29%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20var%20poly_line_87f416d8f037407bbfd415dd8f0f89fb%20%3D%20L.polyline%28%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%5B%5B-1.3933%2C%2036.737899999999996%5D%2C%20%5B-1.3933%2C%2036.9379%5D%2C%20%5B-1.1932999999999998%2C%2036.9379%5D%2C%20%5B-1.1932999999999998%2C%2036.737899999999996%5D%2C%20%5B-1.3933%2C%2036.737899999999996%5D%5D%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7B%22bubblingMouseEvents%22%3A%20true%2C%20%22color%22%3A%20%22red%22%2C%20%22dashArray%22%3A%20null%2C%20%22dashOffset%22%3A%20null%2C%20%22fill%22%3A%20false%2C%20%22fillColor%22%3A%20%22red%22%2C%20%22fillOpacity%22%3A%200.2%2C%20%22fillRule%22%3A%20%22evenodd%22%2C%20%22lineCap%22%3A%20%22round%22%2C%20%22lineJoin%22%3A%20%22round%22%2C%20%22noClip%22%3A%20false%2C%20%22opacity%22%3A%200.8%2C%20%22smoothFactor%22%3A%201.0%2C%20%22stroke%22%3A%20true%2C%20%22weight%22%3A%203%7D%0A%20%20%20%20%20%20%20%20%20%20%20%20%29.addTo%28map_570c6dc6564f4a52a28d3e22f33a7c96%29%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20var%20lat_lng_popup_674d429e12d74a77ac7031d28838318a%20%3D%20L.popup%28%29%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20function%20latLngPop%28e%29%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20lat_lng_popup_674d429e12d74a77ac7031d28838318a%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20.setLatLng%28e.latlng%29%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20.setContent%28%22Latitude%3A%20%22%20%2B%20e.latlng.lat.toFixed%284%29%20%2B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22%3Cbr%3ELongitude%3A%20%22%20%2B%20e.latlng.lng.toFixed%284%29%29%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20.openOn%28map_570c6dc6564f4a52a28d3e22f33a7c96%29%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20map_570c6dc6564f4a52a28d3e22f33a7c96.on%28%27click%27%2C%20latLngPop%29%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%0A%3C/script%3E onload=\"this.contentDocument.open();this.contentDocument.write(    decodeURIComponent(this.getAttribute('data-html')));this.contentDocument.close();\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
      ],
      "text/plain": [
       "<folium.folium.Map at 0x7ff9b6c8cd90>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the area of interest.\n",
    "central_lat = -1.2933\n",
    "central_lon =  36.8379\n",
    "\n",
    "lat_buffer = 0.1\n",
    "lon_buffer = 0.1\n",
    "\n",
    "# Combine lat, lon with their respective buffers to get area of interest.\n",
    "lat_range = (central_lat - lat_buffer, central_lat + lat_buffer)\n",
    "lon_range = (central_lon - lon_buffer, central_lon + lon_buffer)\n",
    "\n",
    "# Time frame for the analysis.\n",
    "time_range = (\"2020-01\", \"2020-04\")\n",
    "\n",
    "# View the study area\n",
    "display_map(x=lon_range, y=lat_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57d96aa1-b1ab-4520-9fb3-32a7f858266c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pixel quality parameters for Sentinel 1\n",
      "Finding datasets\n",
      "    s1_rtc\n",
      "Applying pixel quality/cloud mask\n",
      "Loading 30 time steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CPLReleaseMutex: Error = 1 (Operation not permitted)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:      (time: 30, y: 1276, x: 965)\n",
      "Coordinates:\n",
      "  * time         (time) datetime64[ns] 2020-01-04T15:56:20.113636 ... 2020-04...\n",
      "  * y            (y) float64 -1.522e+05 -1.522e+05 ... -1.777e+05 -1.777e+05\n",
      "  * x            (x) float64 3.545e+06 3.545e+06 ... 3.564e+06 3.564e+06\n",
      "    spatial_ref  int32 6933\n",
      "Data variables:\n",
      "    vv           (time, y, x) float32 0.2355 0.1498 0.08076 ... 0.2787 0.2009\n",
      "    vh           (time, y, x) float32 0.05043 0.04586 ... 0.08394 0.06705\n",
      "Attributes:\n",
      "    crs:           EPSG:6933\n",
      "    grid_mapping:  spatial_ref\n"
     ]
    }
   ],
   "source": [
    "## Load Sentinel 1 data\n",
    "query = {\n",
    "    \"y\": lat_range,\n",
    "    \"x\": lon_range,\n",
    "    \"time\": time_range,\n",
    "    \"output_crs\": \"EPSG:6933\",\n",
    "    \"resolution\": (-20, 20),\n",
    "}\n",
    "\n",
    "ds = load_ard(\n",
    "    dc=dc, products=[\"s1_rtc\"], measurements=[\"vv\", \"vh\"], group_by=\"solar_day\", **query\n",
    ")\n",
    "\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86a595e-695b-47a8-afb8-996c517eda08",
   "metadata": {},
   "source": [
    "## Test 1 : Performance of sklearn_flatten, raster_stack and raster_stack2 on a dataset with NaNs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549bf42e-dddb-4b6b-b096-8f8113c43be2",
   "metadata": {},
   "source": [
    "The following test shows the difference between the output of raster_stack , raster_stack2 and sklearn_flatten. \n",
    "Unlike sklearn_flatten and raster_stack2, raster_stack does not drop the NaN's but fills them with an arbitrary value `-9999`.\n",
    "This results in the difference in the shape and values of the raster_stack and sklearn_flatten and raster_stack2 values. \n",
    "The raster_stack function is the fastest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "318d7f98-71e9-447c-bf2f-91862ddd7313",
   "metadata": {},
   "outputs": [],
   "source": [
    "def raster_stack(input_xr):\n",
    "    \"\"\"\n",
    "    Reshape a DataArray or Dataset with spatial (and optionally\n",
    "    temporal) structure into an np.array with the spatial and temporal\n",
    "    dimensions flattened into one dimension.\n",
    "    This flattening procedure enables DataArrays and Datasets to be used\n",
    "    to train and predict with sklearn models.\n",
    "\n",
    "    Last modified: December 2021\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_xr : xarray.DataArray or xarray.Dataset\n",
    "        Must have dimensions 'x' and 'y', may have dimension 'time'.\n",
    "        Dimensions other than 'x', 'y' and 'time' are unaffected by the\n",
    "        flattening.\n",
    "    Returns\n",
    "    ----------\n",
    "    input_np : numpy.array\n",
    "        A numpy array corresponding to input_xr.data (or\n",
    "        input_xr.to_array().data), with dimensions 'x','y' and 'time'\n",
    "        flattened into a single dimension, which is the first axis of\n",
    "        the returned array. input_np contains no NaNs.\n",
    "    \"\"\"\n",
    "\n",
    "    # Cast input Datasets to DataArray.\n",
    "    if isinstance(input_xr, xr.Dataset):\n",
    "        input_xr = input_xr.to_array()\n",
    "        \n",
    "    # Fill the Nan's in the dataset.\n",
    "    # input_xr = input_xr.fillna(-9999)\n",
    "  \n",
    "    # Get the input_xr's data as a numpy.ndarray.\n",
    "    input_xr_npa = input_xr.values\n",
    "    \n",
    "    # Define function to flatten and drop NaNs from a numpy array. \n",
    "    def flatten_drop_nan(np_array):\n",
    "        np_flattened = np_array.flatten(order=\"F\")\n",
    "        np_drop_nan = np_flattened[np.logical_not(np.isnan(np_flattened))]\n",
    "        return np_drop_nan\n",
    "   \n",
    "    # Flatten the numpy array.\n",
    "    input_xr_flattened_npa = np.array([flatten_drop_nan(input_xr_npa[i]) for i in range(input_xr_npa.shape[0])])\n",
    "  \n",
    "    # Transpose the flattened numpy array to get the shape (n_samples, n_features)\n",
    "    # where n_features is the number of bands and n_samples is the total number of pixels in each band.\n",
    "    input_np = input_xr_flattened_npa.T\n",
    "\n",
    "    return input_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a29c29c-cc31-41d3-a1a1-f2b229558dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:      (time: 30, y: 1276, x: 965)\n",
      "Coordinates:\n",
      "  * time         (time) datetime64[ns] 2020-01-04T15:56:20.113636 ... 2020-04...\n",
      "  * y            (y) float64 -1.522e+05 -1.522e+05 ... -1.777e+05 -1.777e+05\n",
      "  * x            (x) float64 3.545e+06 3.545e+06 ... 3.564e+06 3.564e+06\n",
      "    spatial_ref  int32 6933\n",
      "Data variables:\n",
      "    vv           (time, y, x) float32 0.2355 0.1498 0.08076 ... 0.2787 0.2009\n",
      "    vh           (time, y, x) float32 0.05043 0.04586 ... 0.08394 0.06705\n",
      "Attributes:\n",
      "    crs:           EPSG:6933\n",
      "    grid_mapping:  spatial_ref\n"
     ]
    }
   ],
   "source": [
    "# The ds dataset contains NaNs.\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1c8e6ed-ae76-40b0-9a2b-77ea31f16fd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1781184"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of NaNs in the ds Dataset.\n",
    "np.count_nonzero(np.isnan(ds.to_array().values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e74c910b-e51f-4c67-9d8e-fe62c0d89afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.42 s, sys: 573 ms, total: 1.99 s\n",
      "Wall time: 1.99 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.23554994, 0.0504317 ],\n",
       "       [0.13722907, 0.05083345],\n",
       "       [0.4322208 , 0.13801377],\n",
       "       ...,\n",
       "       [0.19534045, 0.08038338],\n",
       "       [0.31594756, 0.07598579],\n",
       "       [0.20093839, 0.067047  ]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time sklearn_flatten(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e2fbeae-28f0-479d-98c5-185f7135dd40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 493 ms, sys: 264 ms, total: 757 ms\n",
      "Wall time: 755 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.23554994, 0.0504317 ],\n",
       "       [0.13722907, 0.05083345],\n",
       "       [0.4322208 , 0.13801377],\n",
       "       ...,\n",
       "       [0.19534045, 0.08038338],\n",
       "       [0.31594756, 0.07598579],\n",
       "       [0.20093839, 0.067047  ]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time raster_stack(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7fd4f25-ee1f-4983-af72-bbe7de2f2ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36049608, 2)\n",
      "(36049608, 2)\n"
     ]
    }
   ],
   "source": [
    "X = sklearn_flatten(ds)\n",
    "X1 = raster_stack(ds)\n",
    "print(X.shape)\n",
    "print(X1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7cea396-ca63-4058-9a8b-30bfa4869379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate if the output of sklearn_flatten and raster_stack are equal.\n",
    "np.unique(X == X1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc6c1a3-d458-4091-ae40-86e374e98f3a",
   "metadata": {},
   "source": [
    "## Test 2 : Performance of sklearn_flatten, raster_stack and raster_stack2 on a dataset without NaNs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859643db-094d-489d-8b3b-034b7f6b9aee",
   "metadata": {},
   "source": [
    "On a dataset with no NaNS the sklearn_flatten, raster_stack and raster_stack2 functions all have the same output.\n",
    "The raster_stack function is the fastest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee1211e9-93d6-44e5-b735-843def946f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:      (y: 1276, x: 965)\n",
      "Coordinates:\n",
      "  * y            (y) float64 -1.522e+05 -1.522e+05 ... -1.777e+05 -1.777e+05\n",
      "  * x            (x) float64 3.545e+06 3.545e+06 ... 3.564e+06 3.564e+06\n",
      "    spatial_ref  int32 6933\n",
      "Data variables:\n",
      "    vv           (y, x) float32 0.1607 0.178 0.1652 ... 0.1377 0.171 0.1869\n",
      "    vh           (y, x) float32 0.05063 0.04961 0.03781 ... 0.03357 0.04337\n"
     ]
    }
   ],
   "source": [
    "# The ds_median Dataset does not have any NaNs.\n",
    "ds_median = ds.median(dim=\"time\")\n",
    "print(ds_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f219e130-e1e7-4ed3-8e82-63afc238696e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of NaNs in the ds_median Dataset.\n",
    "np.count_nonzero(np.isnan(ds_median.to_array().values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b98b0373-e3c4-40b4-8829-019586474b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 39.4 ms, sys: 14.5 ms, total: 53.9 ms\n",
      "Wall time: 53.3 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.16067713, 0.05063258],\n",
       "       [0.181238  , 0.04633285],\n",
       "       [0.17403632, 0.0490597 ],\n",
       "       ...,\n",
       "       [0.3799113 , 0.07505855],\n",
       "       [0.3147898 , 0.05331162],\n",
       "       [0.18691418, 0.04337489]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time sklearn_flatten(ds_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "496c96e3-7621-44b8-a82e-f6132ccfb0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.8 ms, sys: 0 ns, total: 15.8 ms\n",
      "Wall time: 13.8 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.16067713, 0.05063258],\n",
       "       [0.181238  , 0.04633285],\n",
       "       [0.17403632, 0.0490597 ],\n",
       "       ...,\n",
       "       [0.3799113 , 0.07505855],\n",
       "       [0.3147898 , 0.05331162],\n",
       "       [0.18691418, 0.04337489]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time raster_stack(ds_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6cd3dc5-ea56-4bbb-91e4-613f377eb86c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1231340, 2)\n",
      "(1231340, 2)\n"
     ]
    }
   ],
   "source": [
    "X = sklearn_flatten(ds_median)\n",
    "X1 = raster_stack(ds_median)\n",
    "print(X.shape)\n",
    "print(X1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "171f59c2-52a5-47d0-ba3f-7345371fd812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate if the output of sklearn_flatten and raster_stack are equal.\n",
    "np.unique(X == X1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1982e6b7-f776-4ff3-aaf7-107c81133666",
   "metadata": {},
   "source": [
    "## Test 3 : Performance of sklearn_unflatten, raster_unstack on a dataset with NaNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f4bede3-e5a8-4ca7-887e-bdd37df51c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datacube.utils.geometry import assign_crs\n",
    "\n",
    "def raster_unstack(output_np, input_xr):\n",
    "    \"\"\"\n",
    "    Reshape a numpy array with no 'missing' elements (NaNs) and\n",
    "    'flattened' spatiotemporal structure into a DataArray matching the\n",
    "    spatiotemporal structure of the DataArray\n",
    "    This enables an sklearn model's prediction to be remapped to the\n",
    "    correct pixels in the input DataArray or Dataset.\n",
    "\n",
    "    Last modified: November 2021\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    output_np : numpy.array\n",
    "        The first dimension's length should correspond to the number of\n",
    "        pixels in input_xr.\n",
    "\n",
    "    input_xr : xarray.DataArray or xarray.Dataset\n",
    "        Must have dimensions 'x' and 'y', may have dimension 'time'.\n",
    "        Dimensions other than 'x', 'y' and 'time' are unaffected by the\n",
    "        flattening.\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    output_xr : xarray.DataArray\n",
    "        An xarray.DataArray with the same dimensions 'x', 'y' and 'time'\n",
    "        as input_xr, and the same number of pixels. The pixels\n",
    "        are set to match the data in output_np.\n",
    "    \"\"\"\n",
    "\n",
    "    # The  expected output of a sklearn model prediction should just be\n",
    "    # a 1 dimensional numpy array, output_np, with the size/columns matching\n",
    "    # the y * x * time  for the dimensions of the input_xr DataArray/Dataset.\n",
    "\n",
    "    # Cast input Datasets to DataArray.\n",
    "    if isinstance(input_xr, xr.Dataset):\n",
    "        input_xr = input_xr.to_array()\n",
    "\n",
    "    # Work around for input_xr Dataset with geographic coordinate reference system.\n",
    "    if input_xr.geobox.crs.geographic:\n",
    "        input_xr = input_xr.rename({\"longitude\": \"x\", \"latitude\": \"y\"})\n",
    "\n",
    "    # Get the input_xr's data as a numpy.ndarray.\n",
    "    input_xr_npa = input_xr.values\n",
    "    \n",
    "    # Get the data type of the input_xr_npa numpy array.\n",
    "    data_type = input_xr_npa.dtype\n",
    "\n",
    "    # Flatten the input_xr_npa numpy array.\n",
    "    input_xr_flattened_npa = np.array([input_xr_npa[i].flatten(order=\"F\") for i in range(input_xr_npa.shape[0])])\n",
    "\n",
    "    # Transpose the input_xr_flattened_npa numpy array to get the shape (n_samples, n_features)\n",
    "    # where n_features is the number of bands and n_samples is the total number of pixels in each band.\n",
    "    input_np = input_xr_flattened_npa.T\n",
    "\n",
    "    # Create a mask of the Nans.\n",
    "    mask = np.isnan(input_np)\n",
    "\n",
    "    # Create an empty numpy array..\n",
    "    output_xr_np = np.empty(input_np.shape, dtype=data_type)\n",
    "\n",
    "    # Use the mask to put the data in all the right places. \n",
    "    for i in range(output_xr_np.shape[1]):\n",
    "        arr = output_xr_np[:,i]\n",
    "        mask_arr = mask[:,i]\n",
    "        arr[~mask_arr] = output_np[:,i]\n",
    "        arr[mask_arr] = np.nan\n",
    "\n",
    "    # Reshape the output_np numpy array.\n",
    "    output_xr_np = output_xr_np.T.reshape(input_xr_npa.shape, order=\"F\")\n",
    "\n",
    "    # Get the dimensions for output_xr.\n",
    "    if \"time\" in input_xr.dims:\n",
    "        dims = [\"variable\", \"time\", \"y\", \"x\"]\n",
    "        coords = dict(\n",
    "            time=([\"time\"], input_xr.coords[\"time\"].values),\n",
    "            y=([\"y\"], input_xr.coords[\"y\"].values),\n",
    "            x=([\"x\"], input_xr.coords[\"x\"].values),\n",
    "            spatial_ref=input_xr.coords[\"spatial_ref\"].values,\n",
    "            variable=([\"variable\"], [f\"band_{i}\" for i in range(output_xr_np.shape[0])]),\n",
    "        )\n",
    "    else:\n",
    "        dims = [\"variable\", \"y\", \"x\"]\n",
    "        coords = dict(\n",
    "            y=([\"y\"], input_xr.coords[\"y\"].values),\n",
    "            x=([\"x\"], input_xr.coords[\"x\"].values),\n",
    "            spatial_ref=input_xr.coords[\"spatial_ref\"].values,\n",
    "            variable=([\"variable\"], [f\"band_{i}\" for i in range(output_xr_np.shape[0])]),\n",
    "        )\n",
    "\n",
    "    # Convert the output_np numpy array into a xarray DataArray.\n",
    "    output_xr = xr.DataArray(\n",
    "        data=output_xr_np,\n",
    "        dims=dims,\n",
    "        coords=coords,\n",
    "        attrs=input_xr.attrs,\n",
    "    )\n",
    "    # Assign the output\n",
    "    output_xr = assign_crs(output_xr, input_xr.geobox.crs)\n",
    "    \n",
    "    # Work around for input_xr Dataset with geographic coordinate reference system.\n",
    "    if output_xr.geobox.crs.geographic:\n",
    "        output_xr= output_xr.rename({\"x\": \"longitude\" , \"y\": \"latitude\"})\n",
    "    return output_xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb82a30e-2531-4203-af79-0b1d9a491339",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_array = ds.to_array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2a1b58e-8139-40bb-bbe4-e87406fbf6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the DataArray.\n",
    "X = sklearn_flatten(ds_array)\n",
    "X1 = raster_stack(ds_array)\n",
    "\n",
    "# Unflatten the resulting numpy arrays. \n",
    "Y = sklearn_unflatten(X, ds_array)\n",
    "Y1 = raster_unstack(X1, ds_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae1b924-9a47-4411-837a-ab1008515ba3",
   "metadata": {},
   "source": [
    "The sklearn_flatten returns a DataArray in the dimension order of **variable, x, y and time**. \n",
    "Which is different to how the the DE Africa Datasets or DataArrays are normally presented which is in the dimension order **variable, time, y and x**. \n",
    "\n",
    "The raster_unstack returns a DataArray in the dimension order **variable, time, y and x**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "11090a50-2dbc-480c-a6e6-72cdc6a2543d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('variable', 'time', 'y', 'x')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2, 30, 1276, 965)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(ds_array.dims)\n",
    "ds_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea6cbca3-2bed-446c-ab8c-785e9165afe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('output_dim_0', 'x', 'y', 'time')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2, 965, 1276, 30)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(Y.dims)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d2b7e6d7-a04e-4e7d-b498-073cf311b6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('variable', 'time', 'y', 'x')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2, 30, 1276, 965)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(Y1.dims)\n",
    "Y1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0f0d0d-6dad-417f-9302-6b3e4d901c88",
   "metadata": {},
   "source": [
    "For the purpose of comparison I have transposed the values of the results of the sklearn_unflatten into the dimension order variable, time, y and x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "acde8613-dbba-4fde-90e6-fa07bbc9eb4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 30, 1276, 965)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_t = np.transpose(Y.values, (0,3,2,1))\n",
    "Y_t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd2fe2a-76a2-4055-97d0-e0e0573479a7",
   "metadata": {},
   "source": [
    "When transposed, the values of the sklearn_unflatten are not equal to the original DataArray which is odd because when used on a DataArray that has no NaNs (like in Test 4 below) the two are equal. \n",
    "\n",
    "The same thing happens in the raster_unstack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c9afe695-b641-4724-9295-c2c675a069b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test if the results of the transposed sklearn_unflatten and the ds_array dataArray are equal. \n",
    "np.unique(ds_array.values == Y_t) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b285ef0-7afd-457f-9a9c-52490c997cf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test if the results of the raster_unstack and the ds_array DataArray are equal. \n",
    "np.unique(ds_array.values == Y1.values) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1e13e8a3-9bac-4f96-abe5-db6e42a3ae89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test if the results of raster_unstack and the results of the transposed sklearn_unflatten are equal.\n",
    "np.unique(Y_t == Y1.values) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2387e449-09cd-4bc1-8ac3-4ad593b312cb",
   "metadata": {},
   "source": [
    "Time the sklearn_unflatten and the raster_unstack functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dfdc3725-ffe9-4f0f-97c3-208888990077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 1s, sys: 5.4 s, total: 2min 6s\n",
      "Wall time: 2min 6s\n"
     ]
    }
   ],
   "source": [
    "%time Y = sklearn_unflatten(X, ds_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bbbe7351-f949-43e4-9bed-7ebad69e9a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 506 ms, sys: 192 ms, total: 698 ms\n",
      "Wall time: 696 ms\n"
     ]
    }
   ],
   "source": [
    "%time Y1 = raster_unstack(X1, ds_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b92f2d-d68b-4d66-b12d-60521f251ff3",
   "metadata": {},
   "source": [
    "## Test 4: Performance of sklearn_flatten, raster_unstack on a dataset without NaNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c099bd93-fc66-4258-ac82-5a1a0fb32385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the ds_median Dataset to a DataArray.\n",
    "ds_median_array = ds_median.to_array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "af4707c5-d5b7-4f0e-884d-844319410594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of Nans in the ds_median_array DataArray. \n",
    "np.count_nonzero(np.isnan(ds_median_array.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6beec165-e7fb-4ab8-a5ba-1b35ffa96c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the DataArray.\n",
    "X = sklearn_flatten(ds_median_array)\n",
    "X1 = raster_stack(ds_median_array)\n",
    "\n",
    "# Unflatten the resulting numpy arrays. \n",
    "Y = sklearn_unflatten(X, ds_median_array)\n",
    "Y1 = raster_unstack(X1, ds_median_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db101df1-f28c-4830-97cc-36d18a4e32dd",
   "metadata": {},
   "source": [
    "The sklearn_flatten returns a DataArray in the dimension order of **variable, x, y and time**. \n",
    "Which is different to how the the DE Africa Datasets or DataArrays are normally presented which is in the dimension order **variable, time, y and x**. \n",
    "\n",
    "The raster_unstack returns a DataArray in the dimension order **variable, time, y and x**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bcc5769c-b9de-4743-85da-216e86f3fdb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('variable', 'y', 'x')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2, 1276, 965)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(ds_median_array.dims)\n",
    "ds_median_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d6abe896-2a53-47ac-b083-b7b42f454167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('output_dim_0', 'x', 'y')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2, 965, 1276)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(Y.dims)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d0f615c5-4184-4d7d-97b8-1e32a85c2a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('variable', 'y', 'x')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2, 1276, 965)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(Y1.dims)\n",
    "Y1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8d9fe9-e055-4a80-bbb2-dbd3f6202946",
   "metadata": {},
   "source": [
    "For the purpose of comparison I have transposed the values of the results of the sklearn_unflatten into the dimension order variable, time, y and x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "76287ab9-a1e0-4b8e-b283-09a49f10a0a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1276, 965)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_t = np.transpose(Y.values, (0,2,1))\n",
    "Y_t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c5ab8d-994f-4fc4-ac9a-d3accae6b385",
   "metadata": {},
   "source": [
    "The results of the sklearn_unflatten when transposed, the results of the raster_unstack and the ds_median_array are equal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5536af41-28f2-4659-8e5a-89a9f0d435be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test if the results of the transposed sklearn_unflatten and the ds_median_array dataArray are equal. \n",
    "np.unique(ds_median_array.values == Y_t) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cc72d1a2-6126-436a-b2a0-30aa19bad291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test if the results of the raster_unstack and the ds_median_array dataArray are equal. \n",
    "np.unique(ds_median_array.values == Y1.values) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "51e50d92-fa7c-4c72-b297-cd9055704a04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test if the results of raster_unstack and the results of the transposed sklearn_unflatten are equal.\n",
    "np.unique(Y_t == Y1.values) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200d9dd0-e13d-45b1-b025-7173f6e2c3d7",
   "metadata": {},
   "source": [
    "Time the sklearn_unflatten and the raster_unstack functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9aafcfae-9bc5-46d9-a019-9c789e53f4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 235 ms, sys: 92.3 ms, total: 327 ms\n",
      "Wall time: 326 ms\n"
     ]
    }
   ],
   "source": [
    "%time Y = sklearn_unflatten(X, ds_median_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1c6b1835-9b7c-41ea-80ac-c90e50bd4c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.6 ms, sys: 43 µs, total: 16.6 ms\n",
      "Wall time: 15.8 ms\n"
     ]
    }
   ],
   "source": [
    "%time Y1 = raster_unstack(X1, ds_median_array)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
